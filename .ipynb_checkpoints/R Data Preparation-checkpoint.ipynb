{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This guide was written in R 3.2.3.\n",
    "\n",
    "\n",
    "### R and R Studio\n",
    "\n",
    "Install [R](https://www.r-project.org/) and [R Studio](https://www.rstudio.com/products/rstudio/download/).\n",
    "\n",
    "Next, to install the R packages, cd into your workspace, and enter the following, very simple, command into your bash: \n",
    "\n",
    "```\n",
    "R\n",
    "```\n",
    "\n",
    "This will prompt a session in R! From here, you can install any needed packages. For the sake of this tutorial, enter the following into your terminal R session:\n",
    "\n",
    "```\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"downloader\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We've gone over Data Acquisition as of now, so we know how to <i>get</i> our data. But once you have the data, it might not be in the best shape. You might have scraped a bunch of data from a website, but need it in the form of a dataframe to work with it in an easier manner. This process is called data preparation - preparing your data in a format that's easiest to form with.\n",
    "\n",
    "### Overview\n",
    "\n",
    "<b> Data Acquisition: </b> Reading and writing with a variety of file formats and databases. <br>\n",
    "<b> Preparation: </b> Cleaning, munging, combining, normalizing, reshaping, slicing and dicing, and transforming data for analysis. <br>\n",
    "<b> Transformation: </b> Applying mathematical and statistical operations to groups of data sets to derive new data sets. For example, aggregating a large table by group variables. <br>\n",
    "<b> Modeling and computation: </b> Connecting your data to statistical models, machine learning algorithms, or other computational tools <br>\n",
    "<b> Presentation: </b> Creating interactive or static graphical visualizations or textual summaries <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging\n",
    "\n",
    "If you encounter two different datasets that contain the same type of information, you might consider merging them for your analyses. This is yet another functionality built into `pandas`. \n",
    "\n",
    "Let's go through an example containing student data. `d1` contains 5 of the samples and `d2` contains 2 of them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First.Name Last.Name\n",
      "1     Lesley   Cordero\n",
      "2       Ojas     Sathe\n",
      "3      Helen      Chen\n",
      "4        Eli  Epperson\n",
      "5      Jacob Greenberg\n"
     ]
    }
   ],
   "source": [
    "d1 <- read.csv(\"./names_original.csv\")\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name Last Name\n",
      "0     Martin     Perez\n",
      "1      Menna   Elsayed\n"
     ]
    }
   ],
   "source": [
    "d2 = pd.read_csv(\"./names_add.csv\")\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation \n",
    "\n",
    "Instead of working with two separate datasets, it's much easier to simply merge, so we do this with the `concat()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name  Last Name\n",
      "0     Lesley    Cordero\n",
      "1       Ojas      Sathe\n",
      "2      Helen       Chen\n",
      "3        Eli   Epperson\n",
      "4      Jacob  Greenberg\n",
      "0     Martin      Perez\n",
      "1      Menna    Elsayed\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([d1,d2])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might be asking what will happen if one of the datasets has more columns than other - will they still be allowed to merge? Let's try this example with another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name Last Name                   Major\n",
      "0     Martin     Perez  Mechanical Engineering\n",
      "1      Menna   Elsayed               Sociology\n"
     ]
    }
   ],
   "source": [
    "d3 = pd.read_csv(\"./names_extra.csv\")\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the same `concat()` function, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name  Last Name                   Major\n",
      "0     Lesley    Cordero                     NaN\n",
      "1       Ojas      Sathe                     NaN\n",
      "2      Helen       Chen                     NaN\n",
      "3        Eli   Epperson                     NaN\n",
      "4      Jacob  Greenberg                     NaN\n",
      "0     Martin      Perez  Mechanical Engineering\n",
      "1      Menna    Elsayed               Sociology\n"
     ]
    }
   ],
   "source": [
    "result1 = pd.concat([d1, d3])\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `NaN` values - these are undefined values indicating there wasn't any data to be displayed. `pandas` will simply fill in the missing data for each sample where it's unavailable:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       NaN\n",
      "0    Mechanical Engineering\n",
      "Name: Major, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(result1['Major'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "Now, how do we merge two datasets with differing columns? Well, let's take a look at our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dorm            Name\n",
      "0  East Campus      Helen Chen\n",
      "1     Broadway   Danielle Jing\n",
      "2      Shapiro    Craig Rhodes\n",
      "3         Watt  Lesley Cordero\n",
      "4  East Campus    Martin Perez\n",
      "5     Broadway   Menna Elsayed\n",
      "6      Wallach   Will Essilfie\n"
     ]
    }
   ],
   "source": [
    "h1 = pd.read_csv(\"./housing.csv\")\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dorm Street    Cost\n",
      "0     Broadway  114th    9000\n",
      "1      Shapiro  115th    9500\n",
      "2         Watt  113th   10500\n",
      "3  East Campus  116th  11,000\n",
      "4      Wallach  114th    9500\n"
     ]
    }
   ],
   "source": [
    "h2 = pd.read_csv(\"./dorms.csv\")\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `merge()` function in pandas, we can specify which column to merge on and what kind of join to specify. By default merge does an 'inner' join, but here we set it to a left join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dorm            Name Street    Cost\n",
      "0  East Campus      Helen Chen  116th  11,000\n",
      "1     Broadway   Danielle Jing  114th    9000\n",
      "2      Shapiro    Craig Rhodes  115th    9500\n",
      "3         Watt  Lesley Cordero  113th   10500\n",
      "4  East Campus    Martin Perez  116th  11,000\n",
      "5     Broadway   Menna Elsayed  114th    9000\n",
      "6      Wallach   Will Essilfie  114th    9500\n"
     ]
    }
   ],
   "source": [
    "house = pd.merge(h1, h2, on=\"Dorm\", how=\"left\")\n",
    "print(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
